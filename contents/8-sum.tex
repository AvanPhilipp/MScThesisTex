\chapter{Summary} \label{ch:sum}

To use a Xilinx device, the Xilinx software should be used.
The first task was to get familiar with the workflow of an HLS hardware design.
This included the Vivado HLS, the Vivado and the PYNQ system as well.
To create a working hardware design the developer cannot rely just on the automated software functions but has to know the basic structure of the device.
Therefore the directives can be designed optimised.
The designer also has to know the exact working mechanism of the algorithm to implement.
The algorithms usually executed on a serial execution processor, and it affects the result as well.
For parallel execution, such as a hardware design, the code must be design, with the advantages and limitations of the hardware in mind.

The Xilinx xfOpenCV library was a great help in the development process since the library contains all the required functions.
After validating the required functions an acceleration block was established.
The block has to use dataflow to achieve maximal speed.
The steps of the algorithm are set up as in the original code.
The input of the block is a datastream of 8-bit unsigned data.
The incoming datastream is converted to a \codeword{xf::Mat} format.
For the convolution to work the block has to read in \codeword{kernel\_size-1} lines from the image.
This adds to the latency since every step waits until enough pixel is not present at the input side.
After converting the \codeword{xf:Mat} back to a stream the block feeds the stream to the outer program.
Since it is a streaming and dataflow system, the next image can be passed to the input right after the first, even the output image is not ready yet.
There are 3 functions (the two erode and the dilate) which requires a kernel as an input.
These kernels due to the dataflow property should be passed separately, even if they are all the same.
Since the stream input hides the size of the images, also required to pass the height and width of the image to the block.
These parameters are AXI connections and can be written directly before the start of the processing.

Since the xfOpenCV library does not contain an adaptive threshold, which is a thresholding function that only takes into account the local area of the pixel, the extending was necessary.
The function was designed according to two different approaches.
The first solution was to rework a simple convolution function.
With this, the least error was about 1-2\% of the pixels.
The other implementation was the exact copy of the OpenCV solution.
This used the xfOpenCV Boxfilter function.
The Boxfilter tended to calculate values that differ from the original solution only by 1.
This is not a huge amount of difference, but when other logic is chained after it the error bets larger.
Based on the different delta setting the error differed from 1.2-12.9\% of the pixels.
There was not enough time to measure the exact cause of the difference, why it is a failure.
The thresholding function is replaced by the regular threshold, with an arbitrary 128 value, based on offline Otsu thresh calculations.

The final IP should be tested.
Writing the test environment consisted of assembling the correct functions with OpenCV in C/C++ and run the same pictures through it, as the IP block is loaded.
The two results are compared pixel by pixel and expected to differ in less than the 1\% of the pixels.
The other test required when the adaptive threshold function was replaced with the regular one.
For this, the original python code was modified.
The images were processed by two different preprocess function.
Both results were expected to find the approaching drone in the air.
After validating the correctly applied bounding boxes on the modified function, the system was considered validated.

The final implementation including the PS and the VDMA IP block were measured.
The system uses 5.74\% of the LUTs of the FPGA.
This is the highest requirement on the resources followed by the 3.74\% Flip-Flops and the 3.73\% BRAM.
The 4 DSP used compared to 2520 deployed on the board is marginal.
The system uses so few resources that it even can be deployed to a Zedbord.
15725 LUT 20511 Flip-Flops requirement can fit on the 53,200 LUT 106,400 Flip-Flops equipped XC7Z020 chip.
On the energy side, the most dissipation comes from the ARM cortex-A9.

%!!! Ide kellene m√∂g a POWER reportok!!!!

\clearpage